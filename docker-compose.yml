services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 2g  # Limite de mémoire à 2 Go
          cpus: '1.0'  # Limite à 1 cœur CPU
        reservations:
          memory: 1g  # Réservation de mémoire à 1 Go
          cpus: '0.5'  # Réservation de 0.5 cœur CPU

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8085:8085
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    volumes:
      - ./kui/config.yaml:/etc/kafkaui/dynamic_config.yaml
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 1g  # Limite à 1 Go de mémoire
          cpus: '0.5'  # Limite à 0.5 cœur CPU
        reservations:
          memory: 512m  # Réservation de 512 Mo de mémoire
          cpus: '0.2'  # Réservation de 0.2 cœur CPU

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - 9094:9094
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL    
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 5  
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1 Go
      KAFKA_LOG_CLEANUP_POLICY: delete  # Supprimer les anciens logs
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1 Go
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 60000  # 1 minute
    volumes:
      - kafka_data:/var/lib/kafka
      - ./config/kafka/:/opt/kafka/config/
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 4g  # Limite à 4 Go de mémoire
          cpus: '2.0'  # Limite à 2 cœurs CPU
        reservations:
          memory: 2g  # Réservation de mémoire à 2 Go
          cpus: '1.0'  # Réservation de 1 cœur CPU

  # Service Debezium
  # debezium:
  #   image: debezium/connect:1.9
  #   ports:
  #     - 8083:8083
  #   environment:
  #     CONFIG_STORAGE_TOPIC: my_connect_configs
  #     OFFSET_STORAGE_TOPIC: my_connect_offsets
  #     STATUS_STORAGE_TOPIC: my_connect_statuses
  #     BOOTSTRAP_SERVERS: kafka:9092
  #   links:
  #     - zookeeper
  #     - kafka

  producer-longtime:
    container_name: producer-longtime
    build:
      context: .
      dockerfile: Dockerfile.producer-longtime
    volumes:
      - ./kafka/producer-longtime.py:/app/producer-longtime.py
      - producer_longtime_data:/data
    depends_on:
      - kafka
    command: python3 /app/producer-longtime.py
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 2g  # Limite à 2 Go de mémoire
          cpus: '1.0'  # Limite à 1 cœur CPU
        reservations:
          memory: 1g  # Réservation de mémoire à 1 Go
          cpus: '0.5'  # Réservation de 0.5 cœur CPU

  producer-shorttime:
    container_name: producer-shorttime
    build:
      context: .
      dockerfile: Dockerfile.producer-shorttime
    volumes:
      - ./kafka/producer-shorttime.py:/app/producer-shorttime.py
      - producer_shorttime_data:/data
    depends_on:
      - kafka
    command: python3 /app/producer-shorttime.py
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 1g  # Limite à 1 Go de mémoire
          cpus: '0.5'  # Limite à 0.5 cœur CPU
        reservations:
          memory: 512m  # Réservation de mémoire à 512 Mo
          cpus: '0.2'  # Réservation de 0.2 cœur CPU

  spark-longtime:
    container_name: spark-longtime
    build:
      context: .
      dockerfile: Dockerfile.spark-longtime
    volumes:
      - ./spark/:/app
      - spark_longtime_data:/spark-data
    depends_on:
      - kafka
    command: python3 /app/streaming-longtime.py
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 4g  # Limite à 4 Go de mémoire
          cpus: '1.0'  # Limite à 2 cœurs CPU
        reservations:
          memory: 2g  # Réservation de mémoire à 2 Go
          cpus: '1.0'  # Réservation de 1 cœur CPU

  spark-longtime-raw:
    container_name: spark-longtime-raw
    build:
      context: .
      dockerfile: Dockerfile.spark-longtime-raw
    volumes:
      - ./spark/:/app
      - spark_longtime_data:/spark-data
    depends_on:
      - kafka
    command: python3 /app/streaming-longtime-raw.py
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 4g  # Limite à 4 Go de mémoire
          cpus: '1.0'  # Limite à 2 cœurs CPU
        reservations:
          memory: 2g  # Réservation de mémoire à 2 Go
          cpus: '1.0'  # Réservation de 1 cœur CPU

  spark-shorttime:
    container_name: spark-shorttime
    build:
      context: .
      dockerfile: Dockerfile.spark-shorttime
    volumes:
      - ./spark/:/app
      - spark_shorttime_data:/spark-data
    depends_on:
      - kafka
    command: python3 /app/streaming-shorttime.py
    networks:
      - default
      - Projet2BigData
    deploy:
      resources:
        limits:
          memory: 2g  # Limite à 2 Go de mémoire
          cpus: '1.0'  # Limite à 1 cœur CPU
        reservations:
          memory: 1g  # Réservation de mémoire à 1 Go
          cpus: '0.5'  # Réservation de 0.5 cœur CPU

networks:
  Projet2BigData:
    external: true
  default:
    name: crypto_network

volumes:
  zookeeper_data:
    name: crypto_zookeeper_data
  kafka_data:
    name: crypto_kafka_data
  producer_longtime_data:
    name: crypto_producer_longtime_data
  producer_shorttime_data:
    name: crypto_producer_shorttime_data
  spark_longtime_data:
    name: crypto_spark_longtime_data
  spark_shorttime_data:
    name: crypto_spark_shorttime_data
